# -*- coding: utf-8 -*-
"""Prodigy_Infotech_04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TwBliQIuoCnsSvnzj1nLEpylHFCJAsr4
"""

import shutil
shutil.move("kaggle.json", "/root/.kaggle/kaggle.json")

# Install Kaggle API
!pip install -q kaggle

# Upload Kaggle API key
from google.colab import files
uploaded = files.upload()

# Move Kaggle API key
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset
!kaggle datasets download -d gti-upm/leapgestrecog

# Unzip the dataset
!unzip -q leapgestrecog.zip -d leapgestrecog

# Check the contents of the directory
!ls leapgestrecog

import warnings
warnings.filterwarnings('ignore')

import keras
import matplotlib.pyplot as plt
import os
import cv2
import numpy as np

from keras.layers import Conv2D, Activation, MaxPool2D, Dense, Flatten, Dropout

#@title Datasets
CATEGORIES = ["01_palm", '02_l','03_fist','04_fist_moved','05_thumb','06_index','07_ok','08_palm_moved','09_c','10_down']
IMG_SIZE = 50

data_path = "/content/leapgestrecog/leapGestRecog"

#@title output
image_data = []
for dr in os.listdir(data_path):
    for category in CATEGORIES:
        class_index = CATEGORIES.index(category)
        path = os.path.join(data_path, dr, category)
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)
                image_data.append([cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE)), class_index])
            except Exception as e:
                pass
image_data[0]
# Check the first entry in the image_data list
print("Shape of the first image:", image_data[0][0].shape)
print("Class index of the first image:", image_data[0][1])

#@title shuffle & plot data
import random
random.shuffle(image_data)
input_data = []
label = []
for X, y in image_data:
    input_data.append(X)
    label.append(y)

plt.figure(1, figsize=(10,10))
for i in range(1,10):
    plt.subplot(3,3,i)
    plt.imshow(image_data[i][0], cmap='hot')
    plt.xticks([])
    plt.yticks([])
    plt.title(CATEGORIES[label[i]][3:])
plt.show()

# Normalization
input_data = np.array(input_data)
label = np.array(label)
input_data = input_data/255.0
input_data.shape

label = keras.utils.to_categorical(label, num_classes=10,dtype='i1')
label[0]

#@title reshape
input_data.shape = (-1, IMG_SIZE, IMG_SIZE, 1)

#@title splitting into training & testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(input_data, label, test_size = 0.3, random_state=0)

#@title Building The model
model = keras.models.Sequential()

model.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = (IMG_SIZE, IMG_SIZE, 1)))
model.add(Activation('relu'))


model.add(Conv2D(filters = 32, kernel_size = (3,3)))
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.3))

model.add(Conv2D(filters = 64, kernel_size = (3,3)))
model.add(Activation('relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
             optimizer = 'rmsprop',
             metrics = ['accuracy'])

history = model.fit(X_train, y_train, epochs = 7, batch_size=32, validation_data=(X_test, y_test))

#@title Training History Plot

def plot_training_history(history):
    plt.figure(figsize=(12, 6))

    # Plot training & validation accuracy values
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(['Train', 'Validation'], loc='upper left')

    plt.show()

# Call the function to plot the training history
plot_training_history(history)

model.summary()

#@title confusion matrix
y_pred = model.predict(X_test)

# Convert predictions to class labels
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Plot confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

def plot_confusion_matrix(y_true, y_pred_classes, classes):
    cm = confusion_matrix(y_true, y_pred_classes)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# Call the function to plot the confusion matrix
plot_confusion_matrix(y_true, y_pred_classes, classes=["Class1", "Class2", "Class3", ...])

# Get unique class labels
unique_labels = np.unique(np.argmax(y_test, axis=1))

# Create classes list
classes = [f"Class{label}" for label in unique_labels]

# Define the function to plot sample predictions
def plot_sample_predictions(images, true_labels, pred_labels, classes):
    plt.figure(figsize=(15, 6))
    for i in range(len(images)):
        plt.subplot(1, len(images), i + 1)
        plt.imshow(images[i].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')
        plt.title(f'True: {classes[true_labels[i]]}\nPredicted: {classes[pred_labels[i]]}')
        plt.axis('off')
    plt.show()

# Call the function to plot sample predictions
plot_sample_predictions(sample_images, sample_labels, sample_predictions_classes, classes=classes)